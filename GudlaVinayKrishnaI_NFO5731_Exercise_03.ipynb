{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Movie Review Sentiment Analysis\n",
        "1. **Word Frequency:** This is about counting words in movie reviews. Words like \"amazing\" in good reviews and \"boring\" in bad ones help the computer guess if a review is positive or negative.\n",
        "\n",
        "2. **Sentence Length:** Short sentences might mean a bad review, and long sentences might mean a good one. It's like seeing if the reviewer wanted to say a lot or just a little about the movie.\n",
        "\n",
        "3. **Emotional Tone:** This finds feeling words in reviews. Words that show happiness or anger tell the computer how the person feels about the movie.\n",
        "\n",
        "4. **Negation Words:** Words like \"not\" change the meaning. \"Not bad\" can mean something is good. The computer learns these tricks to better understand the review.\n",
        "\n",
        "5. **Punctuation Usage:** How people use punctuation, like \"!\" or \"...\", can show if they're really excited or not happy. It's a clue for the computer about the review's mood.\n",
        "\n",
        "6. **Use of Capitalization:** Sometimes, when people write reviews, they use ALL CAPS to show they feel strongly about something. For example, \"LOVED IT\" might mean they really enjoyed the movie. This can help the computer see when someone feels very positive or negative about a movie.\n",
        "\n",
        "7.**Thematic Words:** Certain words are directly related to movies, like \"plot,\" \"characters,\" or \"cinematography.\" If a review says positive things about these aspects, it's likely a good review. For example, \"The plot was captivating\" suggests a positive sentiment. This helps the computer understand specific parts of the movie that people liked or didn't like."
      ],
      "metadata": {
        "id": "3i-BnSlcapMT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87a2986b-d07d-4d02-cbe8-dcb64d1bee7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'avg_sentence_length': 12.0, 'word_freq': {'positive': 2, 'negative': 0, 'thematic': 2}, 'negation_count': 0, 'capitalization_count': 2, 'punctuation_count': 2}\n",
            "{'avg_sentence_length': 3.6666666666666665, 'word_freq': {'positive': 0, 'negative': 3, 'thematic': 1}, 'negation_count': 0, 'capitalization_count': 1, 'punctuation_count': 0}\n",
            "{'avg_sentence_length': 3.6666666666666665, 'word_freq': {'positive': 1, 'negative': 0, 'thematic': 1}, 'negation_count': 2, 'capitalization_count': 0, 'punctuation_count': 0}\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "# Sample reviews\n",
        "reviews = [\n",
        "    \"LOVED this movie! The plot was AMAZING and the characters were fantastic!\",\n",
        "    \"This was the WORST movie ever. Boring plot and terrible acting.\",\n",
        "    \"Stunning cinematography, but the plot was not great. Not bad overall.\"\n",
        "]\n",
        "\n",
        "# Words indicating positive or negative sentiment\n",
        "positive_words = ['amazing', 'fantastic', 'loved', 'stunning', 'captivating']\n",
        "negative_words = ['worst', 'boring', 'terrible']\n",
        "\n",
        "# Thematic words related to movies\n",
        "thematic_words = ['plot', 'characters', 'cinematography']\n",
        "\n",
        "def extract_features(text):\n",
        "    # Initialize counters\n",
        "    word_freq = {'positive': 0, 'negative': 0, 'thematic': 0}\n",
        "    negation_count = 0\n",
        "    capitalization_count = 0\n",
        "    punctuation_count = 0\n",
        "\n",
        "    # Split text into sentences and words\n",
        "    sentences = text.split('.')\n",
        "    words = text.split()\n",
        "\n",
        "    # Calculate sentence length feature\n",
        "    avg_sentence_length = sum(len(s.split()) for s in sentences if s) / len(sentences)\n",
        "\n",
        "    # Process each word\n",
        "    for word in words:\n",
        "        # Check for positive/negative words\n",
        "        if word.lower() in positive_words:\n",
        "            word_freq['positive'] += 1\n",
        "        elif word.lower() in negative_words:\n",
        "            word_freq['negative'] += 1\n",
        "\n",
        "        # Check for thematic words\n",
        "        if word.lower() in thematic_words:\n",
        "            word_freq['thematic'] += 1\n",
        "\n",
        "        # Check for negation words\n",
        "        if \"not\" in word.lower():\n",
        "            negation_count += 1\n",
        "\n",
        "        # Check for capitalization\n",
        "        if word.isupper() and len(word) > 1:\n",
        "            capitalization_count += 1\n",
        "\n",
        "    # Count punctuation usage\n",
        "    punctuation_count = text.count('!') + text.count('...')\n",
        "\n",
        "    # Compile features\n",
        "    features = {\n",
        "        'avg_sentence_length': avg_sentence_length,\n",
        "        'word_freq': word_freq,\n",
        "        'negation_count': negation_count,\n",
        "        'capitalization_count': capitalization_count,\n",
        "        'punctuation_count': punctuation_count,\n",
        "    }\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extract and print features for each review\n",
        "for review in reviews:\n",
        "    features = extract_features(review)\n",
        "    print(features)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Emotional Words**: Words that clearly show feelings, like \"love\" for good reviews or \"hate\" for bad ones, tell us a lot about whether someone enjoyed the movie. They're very important because they directly express the reviewer's sentiment.\n",
        "\n",
        "2. **Negation Words**: Words like \"not\" can change the whole meaning of a sentence. For example, \"not good\" actually means something is bad. These are crucial for understanding the real sentiment behind a sentence.\n",
        "\n",
        "3. **ALL CAPS Words**: When people write in ALL CAPS, it often means they're feeling very strongly about what they're saying. For instance, saying \"I LOVED THIS MOVIE\" likely means they really enjoyed it. This is a strong indicator of sentiment.\n",
        "\n",
        "4. **Punctuation Marks**: The use of exclamation marks (!) or ellipses (...) can show how strongly someone feels about their opinion. Lots of exclamation marks might mean excitement or anger, depending on the context.\n",
        "\n",
        "5. **Thematic Words**: Words specific to movies, like \"plot,\" \"characters,\" or \"cinematography,\" are important because they show what aspect of the movie the review is focusing on. While not directly about sentiment, they help us understand what the reviewer is commenting on.\n",
        "\n",
        "6. **Sentence Length**: Longer sentences might be used to describe positive experiences in detail, while shorter sentences could indicate negative feedback. However, this isn't always the case, making sentence length a bit less directly tied to sentiment than other features.\n",
        "\n",
        "7. **General Word Frequency**: This is looking at which words show up a lot, but without focusing on whether they're positive or negative. It's the least direct way to understand sentiment because it's just about word popularity, not meaning.\n",
        "\n"
      ],
      "metadata": {
        "id": "QOp4WPrMiMYA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeecb3d1-5424-4a5c-ce8a-710eef2097de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Worst movie, dull plot and unlikable characters. (Similarity: 0.8904)\n",
            "Loved this movie, amazing plot and characters. (Similarity: 0.8821)\n",
            "Great cinematography but predictable story, okay overall. (Similarity: 0.8420)\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Define your texts and query\n",
        "texts = [\n",
        "    \"Loved this movie, amazing plot and characters.\",\n",
        "    \"Worst movie, dull plot and unlikable characters.\",\n",
        "    \"Great cinematography but predictable story, okay overall.\"\n",
        "]\n",
        "query = \"Amazing movie with interesting characters.\"\n",
        "\n",
        "# Function to encode texts to BERT embeddings\n",
        "def encode(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')\n",
        "    outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state[:, 0, :].squeeze().detach().numpy()\n",
        "\n",
        "# Encode query and texts\n",
        "query_vec = encode(query)\n",
        "text_vecs = torch.stack([torch.tensor(encode(text)) for text in texts])\n",
        "\n",
        "# Calculate cosine similarities\n",
        "cos_sim = cosine_similarity([query_vec], text_vecs)[0]\n",
        "\n",
        "# Rank texts by similarity\n",
        "ranked_texts = [(text, sim) for text, sim in sorted(zip(texts, cos_sim), key=lambda x: x[1], reverse=True)]\n",
        "\n",
        "# Display ranked texts and similarities\n",
        "for text, sim in ranked_texts:\n",
        "    print(f\"{text} (Similarity: {sim:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Experience: I found it interesting to see how text features and BERT model help understand text better. It's cool how we can figure out what a text is saying by looking at things like word choice and sentence structure.\n",
        "\n",
        "Challenges Encountered: The main challenge was dealing with the technical side, like making sure the data was set up right for BERT and figuring out cosine similarity.\n",
        "\n",
        "Relevance to NLP: This exercise is super relevant to NLP (Natural Language Processing) because it's all about teaching computers to understand human language. Learning about text features and BERT is key for making smarter NLP tools."
      ],
      "metadata": {
        "id": "z2NJ7DGYlUxi"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}